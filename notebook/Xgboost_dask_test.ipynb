{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Version: 0.90\n"
     ]
    }
   ],
   "source": [
    "# %load Run_RFR_on_data.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold ,RandomizedSearchCV ,train_test_split, cross_val_predict , cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,classification_report, confusion_matrix,accuracy_score,matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "np.random.seed(seed = 101)\n",
    "import xgboost as xgb; print('XGBoost Version:', xgb.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_df = pd.DataFrame()\n",
    "all_files = [x for x in os.listdir(\"synapse_DREAM_challenge/CELL_LINES/\") if \".csv\" in x and x != \"subchallenge_1_template_data.csv\"  ]\n",
    "\n",
    "\n",
    "target_cell_lines = ['AU565', 'EFM19', 'HCC2218', 'LY2', 'MACLS2', 'MDAMB436']\n",
    "\n",
    "\n",
    "target_genes = ['p.ERK', 'p.Akt.Ser473.', 'p.S6', 'p.HER2', 'p.PLCg2']\n",
    "\n",
    "\n",
    "for m in all_files:\n",
    "    #print (m)\n",
    "    df_temp = dd.read_csv(\"synapse_DREAM_challenge/CELL_LINES/%s\"%m)\n",
    "    big_df = dd.concat([big_df,df_temp],axis=0)\n",
    "\n",
    "\n",
    "train_df = big_df[~big_df[\"cell_line\"].isin(target_cell_lines)]\n",
    "\n",
    "X = train_df.drop(target_genes,axis=1)\n",
    "\n",
    "y = train_df[target_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['treatment', 'cell_line', 'time', 'cellID', 'fileID', 'b.CATENIN',\n",
       "       'cleavedCas', 'CyclinB', 'GAPDH', 'IdU', 'Ki.67', 'p.4EBP1',\n",
       "       'p.Akt.Ser473.', 'p.AKT.Thr308.', 'p.AMPK', 'p.BTK', 'p.CREB', 'p.ERK',\n",
       "       'p.FAK', 'p.GSK3b', 'p.H3', 'p.HER2', 'p.JNK', 'p.MAP2K3', 'p.MAPKAPK2',\n",
       "       'p.MEK', 'p.MKK3.MKK6', 'p.MKK4', 'p.NFkB', 'p.p38', 'p.p53',\n",
       "       'p.p90RSK', 'p.PDPK1', 'p.PLCg2', 'p.RB', 'p.S6', 'p.S6K', 'p.SMAD23',\n",
       "       'p.SRC', 'p.STAT1', 'p.STAT3', 'p.STAT5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_target_ditionary = {'ERK':'p.ERK', 'AKT':'p.Akt.Ser473.', 'S6':'p.S6', 'HER':'p.HER2', 'PLCG2':'p.PLCg2'}\n",
    "\n",
    "#from dask_ml.xgboost import XGBRegressor\n",
    "#base_model = RandomForestRegressor( n_estimators = 1000, random_state = 101,n_jobs=-1,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat4egorize\n",
      "dummies\n"
     ]
    }
   ],
   "source": [
    "print (\"cat4egorize\")\n",
    "\n",
    "X = X.categorize(columns=[\"treatment\"])\n",
    "\n",
    "print (\"dummies\")\n",
    "\n",
    "my_dummies = dd.get_dummies(X[\"treatment\"])\n",
    "\n",
    "\n",
    "X= X.drop(['treatment', 'cell_line', 'time', 'cellID', 'fileID'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in X.columns :\n",
    "#     if len(X[X[m].isna()]) != 0:\n",
    "#         print (m,len(X[X[m].isna()]))\n",
    "    #for m in X.columns :\n",
    "#    X[m].fillna((X[m].mean().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in y.columns :\n",
    "#     if len(y[y[m].isna()]) != 0:\n",
    "#         print (m,len(y[y[m].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20459760-2248286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling NA\n"
     ]
    }
   ],
   "source": [
    "print (\"filling NA\")\n",
    "y = y.compute()\n",
    "# y['p.PLCg2_fill'] = y['p.PLCg2'].fillna(y['p.PLCg2'].mean().compute()  )\n",
    "# y['p.HER2_fill'] = y['p.HER2'].fillna(y['p.HER2'].mean().compute()  )\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# #for m in X.columns :\n",
    "# #    X[m].fillna((X[m].mean().compute()))\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "for m in y.columns :\n",
    "    y[m].fillna(y[m].mean() , inplace=True )\n",
    "# X.fillna(0)\n",
    "# y.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y.drop(['p.PLCg2','p.HER2'],axis=1)\n",
    "# for m in y.columns :\n",
    "#     if len(y[y[m].isna()]) != 0:\n",
    "#         print (m,len(y[y[m].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p.ERK', 'p.Akt.Ser473.', 'p.S6', 'p.HER2', 'p.PLCg2'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = xgb.XGBRegressor(verbosity=2,n_jobs=-1,objective='reg:squarederror')\n",
    "base_model = RandomForestRegressor(verbose=2,n_jobs=-1,random_state=101,n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instantiate params\n",
    "# params = {}\n",
    "\n",
    "# # general params\n",
    "# general_params = {'silent': 1}\n",
    "# params.update(general_params)\n",
    "\n",
    "# # booster params\n",
    "# n_gpus = 1\n",
    "# booster_params = {}\n",
    "\n",
    "# if n_gpus != 0:\n",
    "#     booster_params['tree_method'] = 'gpu_hist'\n",
    "#     booster_params['n_gpus'] = n_gpus\n",
    "# params.update(booster_params)\n",
    "\n",
    "# # learning task params\n",
    "# learning_task_params = {'eval_metric': 'rmse', 'objective': 'reg:tweedie'}\n",
    "# params.update(learning_task_params)\n",
    "# print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler\n"
     ]
    }
   ],
   "source": [
    "print(\"Scaler\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03506847,  1.67391572, -0.84339623, ...,  0.63902696,\n",
       "        -0.28732705, -0.04874762],\n",
       "       [-1.15458435, -0.36247582, -0.69648374, ..., -2.53343822,\n",
       "        -0.95625421, -1.797144  ],\n",
       "       [-1.06581749, -1.24644988, -0.95014624, ..., -0.6328717 ,\n",
       "        -1.08873047,  0.10586511],\n",
       "       ...,\n",
       "       [-1.15382871,  0.97053614, -0.95014624, ...,  0.20882815,\n",
       "        -0.06610757, -0.26242267],\n",
       "       [-1.15458435, -1.24644988, -0.81029226, ..., -0.48433516,\n",
       "        -1.08873047, -0.49845811],\n",
       "       [ 1.4811292 ,  1.34956188, -0.54617928, ...,  0.65249188,\n",
       "         0.53978631, -0.39644473]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(X_scaled)\n",
    "X_scaled[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p.ERK</th>\n",
       "      <th>p.Akt.Ser473.</th>\n",
       "      <th>p.S6</th>\n",
       "      <th>p.HER2</th>\n",
       "      <th>p.PLCg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.985215</td>\n",
       "      <td>3.537355</td>\n",
       "      <td>5.96652</td>\n",
       "      <td>4.988744</td>\n",
       "      <td>2.185986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.923010</td>\n",
       "      <td>0.550685</td>\n",
       "      <td>3.08669</td>\n",
       "      <td>2.420064</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650769</td>\n",
       "      <td>3.308237</td>\n",
       "      <td>4.75636</td>\n",
       "      <td>5.003612</td>\n",
       "      <td>1.653599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.394234</td>\n",
       "      <td>2.917066</td>\n",
       "      <td>5.69939</td>\n",
       "      <td>4.794311</td>\n",
       "      <td>2.457316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.962249</td>\n",
       "      <td>0.550685</td>\n",
       "      <td>3.33093</td>\n",
       "      <td>3.733031</td>\n",
       "      <td>2.208131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.347849</td>\n",
       "      <td>1.669070</td>\n",
       "      <td>5.07211</td>\n",
       "      <td>3.701532</td>\n",
       "      <td>1.379199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.571471</td>\n",
       "      <td>1.774273</td>\n",
       "      <td>2.72194</td>\n",
       "      <td>3.033706</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.520213</td>\n",
       "      <td>3.875774</td>\n",
       "      <td>4.82766</td>\n",
       "      <td>3.802993</td>\n",
       "      <td>2.036127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.730348</td>\n",
       "      <td>3.030022</td>\n",
       "      <td>2.39632</td>\n",
       "      <td>4.183928</td>\n",
       "      <td>3.299247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.237769</td>\n",
       "      <td>3.838371</td>\n",
       "      <td>5.17159</td>\n",
       "      <td>4.003189</td>\n",
       "      <td>3.197022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.973517</td>\n",
       "      <td>3.182352</td>\n",
       "      <td>3.44116</td>\n",
       "      <td>3.245664</td>\n",
       "      <td>1.070324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.099935</td>\n",
       "      <td>4.662877</td>\n",
       "      <td>6.57283</td>\n",
       "      <td>3.522184</td>\n",
       "      <td>3.108742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.569234</td>\n",
       "      <td>2.869548</td>\n",
       "      <td>3.72161</td>\n",
       "      <td>4.823494</td>\n",
       "      <td>2.740394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.295926</td>\n",
       "      <td>1.965053</td>\n",
       "      <td>5.48392</td>\n",
       "      <td>3.936153</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.998118</td>\n",
       "      <td>3.044758</td>\n",
       "      <td>5.34318</td>\n",
       "      <td>4.295323</td>\n",
       "      <td>1.510805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.288241</td>\n",
       "      <td>3.159276</td>\n",
       "      <td>5.21175</td>\n",
       "      <td>5.177177</td>\n",
       "      <td>3.038312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.751476</td>\n",
       "      <td>3.573820</td>\n",
       "      <td>5.97702</td>\n",
       "      <td>4.909233</td>\n",
       "      <td>3.663736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.788141</td>\n",
       "      <td>1.668493</td>\n",
       "      <td>5.72924</td>\n",
       "      <td>3.514908</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.775610</td>\n",
       "      <td>1.700128</td>\n",
       "      <td>2.39632</td>\n",
       "      <td>4.071222</td>\n",
       "      <td>1.519294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.765597</td>\n",
       "      <td>2.625439</td>\n",
       "      <td>3.76772</td>\n",
       "      <td>3.622297</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.669990</td>\n",
       "      <td>2.562803</td>\n",
       "      <td>4.57984</td>\n",
       "      <td>3.637684</td>\n",
       "      <td>1.258341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.071087</td>\n",
       "      <td>3.790030</td>\n",
       "      <td>7.85743</td>\n",
       "      <td>4.737975</td>\n",
       "      <td>2.084134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.092467</td>\n",
       "      <td>2.873960</td>\n",
       "      <td>6.07778</td>\n",
       "      <td>3.587258</td>\n",
       "      <td>1.065009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.733290</td>\n",
       "      <td>2.808588</td>\n",
       "      <td>5.21443</td>\n",
       "      <td>2.644328</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.509787</td>\n",
       "      <td>3.001671</td>\n",
       "      <td>6.49506</td>\n",
       "      <td>3.927163</td>\n",
       "      <td>1.271822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.560813</td>\n",
       "      <td>2.254302</td>\n",
       "      <td>4.20378</td>\n",
       "      <td>4.170835</td>\n",
       "      <td>2.372007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.612875</td>\n",
       "      <td>3.617424</td>\n",
       "      <td>5.97470</td>\n",
       "      <td>4.170061</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.107468</td>\n",
       "      <td>2.598401</td>\n",
       "      <td>5.47890</td>\n",
       "      <td>5.554907</td>\n",
       "      <td>4.127386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.850707</td>\n",
       "      <td>1.579326</td>\n",
       "      <td>4.52779</td>\n",
       "      <td>4.125715</td>\n",
       "      <td>1.818275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.391118</td>\n",
       "      <td>2.552762</td>\n",
       "      <td>4.12675</td>\n",
       "      <td>2.874513</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.092252</td>\n",
       "      <td>3.813818</td>\n",
       "      <td>3.87631</td>\n",
       "      <td>5.645667</td>\n",
       "      <td>4.582474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3.222282</td>\n",
       "      <td>4.329165</td>\n",
       "      <td>5.93665</td>\n",
       "      <td>4.740466</td>\n",
       "      <td>3.689824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.927581</td>\n",
       "      <td>3.735334</td>\n",
       "      <td>7.84134</td>\n",
       "      <td>5.173274</td>\n",
       "      <td>3.289055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.010603</td>\n",
       "      <td>2.148204</td>\n",
       "      <td>5.66570</td>\n",
       "      <td>4.092075</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.838208</td>\n",
       "      <td>1.533501</td>\n",
       "      <td>7.13647</td>\n",
       "      <td>1.917055</td>\n",
       "      <td>1.408890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.117910</td>\n",
       "      <td>1.865869</td>\n",
       "      <td>4.97636</td>\n",
       "      <td>3.863948</td>\n",
       "      <td>1.646970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.963162</td>\n",
       "      <td>0.550685</td>\n",
       "      <td>2.85966</td>\n",
       "      <td>3.257214</td>\n",
       "      <td>1.365202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.963008</td>\n",
       "      <td>2.726619</td>\n",
       "      <td>4.86712</td>\n",
       "      <td>3.200622</td>\n",
       "      <td>1.621774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.582415</td>\n",
       "      <td>1.166039</td>\n",
       "      <td>2.41882</td>\n",
       "      <td>3.359106</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2.032461</td>\n",
       "      <td>3.513329</td>\n",
       "      <td>6.53112</td>\n",
       "      <td>4.022154</td>\n",
       "      <td>2.416184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.656992</td>\n",
       "      <td>2.271857</td>\n",
       "      <td>3.47562</td>\n",
       "      <td>4.481934</td>\n",
       "      <td>1.978839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.836235</td>\n",
       "      <td>1.798468</td>\n",
       "      <td>6.00998</td>\n",
       "      <td>3.698139</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.930812</td>\n",
       "      <td>3.183922</td>\n",
       "      <td>4.12109</td>\n",
       "      <td>4.791176</td>\n",
       "      <td>2.801467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3.615126</td>\n",
       "      <td>3.746199</td>\n",
       "      <td>5.96487</td>\n",
       "      <td>4.594505</td>\n",
       "      <td>2.101042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.204375</td>\n",
       "      <td>2.555202</td>\n",
       "      <td>6.22755</td>\n",
       "      <td>3.832392</td>\n",
       "      <td>1.679089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.994433</td>\n",
       "      <td>2.575841</td>\n",
       "      <td>5.16096</td>\n",
       "      <td>4.771303</td>\n",
       "      <td>3.329527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.855198</td>\n",
       "      <td>2.516276</td>\n",
       "      <td>3.67813</td>\n",
       "      <td>4.614423</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2.162396</td>\n",
       "      <td>3.090425</td>\n",
       "      <td>4.87078</td>\n",
       "      <td>3.263216</td>\n",
       "      <td>1.518939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2.252076</td>\n",
       "      <td>2.564460</td>\n",
       "      <td>4.44591</td>\n",
       "      <td>4.262029</td>\n",
       "      <td>1.832540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.672882</td>\n",
       "      <td>1.429658</td>\n",
       "      <td>4.92181</td>\n",
       "      <td>3.393063</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3.081085</td>\n",
       "      <td>3.342224</td>\n",
       "      <td>4.94351</td>\n",
       "      <td>4.503695</td>\n",
       "      <td>1.613622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2.636292</td>\n",
       "      <td>3.666874</td>\n",
       "      <td>6.04970</td>\n",
       "      <td>4.015765</td>\n",
       "      <td>1.444114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.721581</td>\n",
       "      <td>3.190173</td>\n",
       "      <td>3.97902</td>\n",
       "      <td>2.180291</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.254488</td>\n",
       "      <td>2.865962</td>\n",
       "      <td>4.53311</td>\n",
       "      <td>4.401037</td>\n",
       "      <td>2.588025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3.330593</td>\n",
       "      <td>2.813529</td>\n",
       "      <td>3.55616</td>\n",
       "      <td>4.057428</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.060074</td>\n",
       "      <td>1.915050</td>\n",
       "      <td>5.11760</td>\n",
       "      <td>3.721183</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.442259</td>\n",
       "      <td>1.817147</td>\n",
       "      <td>2.39632</td>\n",
       "      <td>2.804964</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.761281</td>\n",
       "      <td>3.202576</td>\n",
       "      <td>5.10230</td>\n",
       "      <td>3.422229</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.258852</td>\n",
       "      <td>1.394485</td>\n",
       "      <td>3.76102</td>\n",
       "      <td>3.342612</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.976077</td>\n",
       "      <td>3.305257</td>\n",
       "      <td>6.37413</td>\n",
       "      <td>4.599161</td>\n",
       "      <td>2.565393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p.ERK  p.Akt.Ser473.     p.S6    p.HER2   p.PLCg2\n",
       "0   1.985215       3.537355  5.96652  4.988744  2.185986\n",
       "1   1.923010       0.550685  3.08669  2.420064  0.986227\n",
       "2   0.650769       3.308237  4.75636  5.003612  1.653599\n",
       "3   4.394234       2.917066  5.69939  4.794311  2.457316\n",
       "4   0.962249       0.550685  3.33093  3.733031  2.208131\n",
       "5   2.347849       1.669070  5.07211  3.701532  1.379199\n",
       "6   2.571471       1.774273  2.72194  3.033706  0.986227\n",
       "7   3.520213       3.875774  4.82766  3.802993  2.036127\n",
       "8   1.730348       3.030022  2.39632  4.183928  3.299247\n",
       "9   3.237769       3.838371  5.17159  4.003189  3.197022\n",
       "10  1.973517       3.182352  3.44116  3.245664  1.070324\n",
       "11  4.099935       4.662877  6.57283  3.522184  3.108742\n",
       "12  2.569234       2.869548  3.72161  4.823494  2.740394\n",
       "13  1.295926       1.965053  5.48392  3.936153  0.986227\n",
       "14  1.998118       3.044758  5.34318  4.295323  1.510805\n",
       "15  4.288241       3.159276  5.21175  5.177177  3.038312\n",
       "16  2.751476       3.573820  5.97702  4.909233  3.663736\n",
       "17  0.788141       1.668493  5.72924  3.514908  0.986227\n",
       "18  1.775610       1.700128  2.39632  4.071222  1.519294\n",
       "19  2.765597       2.625439  3.76772  3.622297  0.986227\n",
       "20  2.669990       2.562803  4.57984  3.637684  1.258341\n",
       "21  3.071087       3.790030  7.85743  4.737975  2.084134\n",
       "22  1.092467       2.873960  6.07778  3.587258  1.065009\n",
       "23  0.733290       2.808588  5.21443  2.644328  0.986227\n",
       "24  1.509787       3.001671  6.49506  3.927163  1.271822\n",
       "25  2.560813       2.254302  4.20378  4.170835  2.372007\n",
       "26  2.612875       3.617424  5.97470  4.170061  0.986227\n",
       "27  3.107468       2.598401  5.47890  5.554907  4.127386\n",
       "28  0.850707       1.579326  4.52779  4.125715  1.818275\n",
       "29  1.391118       2.552762  4.12675  2.874513  0.986227\n",
       "..       ...            ...      ...       ...       ...\n",
       "70  2.092252       3.813818  3.87631  5.645667  4.582474\n",
       "71  3.222282       4.329165  5.93665  4.740466  3.689824\n",
       "72  2.927581       3.735334  7.84134  5.173274  3.289055\n",
       "73  2.010603       2.148204  5.66570  4.092075  0.986227\n",
       "74  1.838208       1.533501  7.13647  1.917055  1.408890\n",
       "75  1.117910       1.865869  4.97636  3.863948  1.646970\n",
       "76  1.963162       0.550685  2.85966  3.257214  1.365202\n",
       "77  0.963008       2.726619  4.86712  3.200622  1.621774\n",
       "78  1.582415       1.166039  2.41882  3.359106  0.986227\n",
       "79  2.032461       3.513329  6.53112  4.022154  2.416184\n",
       "80  0.656992       2.271857  3.47562  4.481934  1.978839\n",
       "81  1.836235       1.798468  6.00998  3.698139  0.986227\n",
       "82  0.930812       3.183922  4.12109  4.791176  2.801467\n",
       "83  3.615126       3.746199  5.96487  4.594505  2.101042\n",
       "84  1.204375       2.555202  6.22755  3.832392  1.679089\n",
       "85  1.994433       2.575841  5.16096  4.771303  3.329527\n",
       "86  1.855198       2.516276  3.67813  4.614423  0.986227\n",
       "87  2.162396       3.090425  4.87078  3.263216  1.518939\n",
       "88  2.252076       2.564460  4.44591  4.262029  1.832540\n",
       "89  0.672882       1.429658  4.92181  3.393063  0.986227\n",
       "90  3.081085       3.342224  4.94351  4.503695  1.613622\n",
       "91  2.636292       3.666874  6.04970  4.015765  1.444114\n",
       "92  1.721581       3.190173  3.97902  2.180291  0.986227\n",
       "93  1.254488       2.865962  4.53311  4.401037  2.588025\n",
       "94  3.330593       2.813529  3.55616  4.057428  0.986227\n",
       "95  2.060074       1.915050  5.11760  3.721183  0.986227\n",
       "96  0.442259       1.817147  2.39632  2.804964  0.986227\n",
       "97  2.761281       3.202576  5.10230  3.422229  0.986227\n",
       "98  1.258852       1.394485  3.76102  3.342612  0.986227\n",
       "99  2.976077       3.305257  6.37413  4.599161  2.565393\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(y)\n",
    "y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERK p.ERK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1000\n",
      "building tree 2 of 1000\n",
      "building tree 3 of 1000\n",
      "building tree 4 of 1000\n",
      "building tree 5 of 1000\n",
      "building tree 6 of 1000\n",
      "building tree 7 of 1000\n",
      "building tree 8 of 1000\n",
      "building tree 9 of 1000\n",
      "building tree 10 of 1000\n",
      "building tree 11 of 1000\n",
      "building tree 12 of 1000\n",
      "building tree 13 of 1000\n",
      "building tree 14 of 1000\n",
      "building tree 15 of 1000\n",
      "building tree 16 of 1000\n",
      "building tree 17 of 1000\n",
      "building tree 18 of 1000\n",
      "building tree 19 of 1000\n",
      "building tree 20 of 1000\n",
      "building tree 21 of 1000\n",
      "building tree 22 of 1000\n",
      "building tree 23 of 1000\n",
      "building tree 24 of 1000\n",
      "building tree 25 of 1000\n",
      "building tree 26 of 1000\n",
      "building tree 27 of 1000\n",
      "building tree 28 of 1000\n",
      "building tree 29 of 1000\n",
      "building tree 30 of 1000\n",
      "building tree 31 of 1000\n",
      "building tree 32 of 1000\n",
      "building tree 33 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 102.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 34 of 1000\n",
      "building tree 35 of 1000\n",
      "building tree 36 of 1000\n",
      "building tree 37 of 1000\n",
      "building tree 38 of 1000\n",
      "building tree 39 of 1000\n",
      "building tree 40 of 1000\n",
      "building tree 41 of 1000\n",
      "building tree 42 of 1000\n",
      "building tree 43 of 1000\n",
      "building tree 44 of 1000\n",
      "building tree 45 of 1000\n",
      "building tree 46 of 1000\n",
      "building tree 47 of 1000\n",
      "building tree 48 of 1000\n",
      "building tree 49 of 1000\n",
      "building tree 50 of 1000\n",
      "building tree 51 of 1000\n",
      "building tree 52 of 1000\n",
      "building tree 53 of 1000\n",
      "building tree 54 of 1000\n",
      "building tree 55 of 1000\n",
      "building tree 56 of 1000\n",
      "building tree 57 of 1000\n",
      "building tree 58 of 1000\n",
      "building tree 59 of 1000\n",
      "building tree 60 of 1000\n",
      "building tree 61 of 1000\n",
      "building tree 62 of 1000\n",
      "building tree 63 of 1000\n",
      "building tree 64 of 1000\n",
      "building tree 65 of 1000\n",
      "building tree 66 of 1000\n",
      "building tree 67 of 1000\n",
      "building tree 68 of 1000\n",
      "building tree 69 of 1000\n",
      "building tree 70 of 1000\n",
      "building tree 71 of 1000\n",
      "building tree 72 of 1000\n",
      "building tree 73 of 1000\n"
     ]
    }
   ],
   "source": [
    "my_results = []\n",
    "my_dict = {}\n",
    "for key in my_target_ditionary.keys():\n",
    "    print (key,my_target_ditionary[key])\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_scaled[:100] , y[my_target_ditionary[key]][:100], test_size=0.33, random_state=101)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled , y[my_target_ditionary[key]], test_size=0.33, random_state=101)\n",
    "    #print (type(y_train))\n",
    "    base_model.fit(X_train,y_train )\n",
    "    #dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    #dvalidation = xgb.DMatrix(X_test, label=y_test)\n",
    "    #dtrain = xgb.DMatrix(X_train)\n",
    "    #dvalidation = xgb.DMatrix(X_test)\n",
    "    \n",
    "# model training settings\n",
    "    #evallist = [(dvalidation, 'validation'), (dtrain, 'train')]\n",
    "    #num_round = 2\n",
    "    #base_model.fit(params, dtrain,y_train )\n",
    "    #base_model.train(params, dtrain, num_round, evallist)\n",
    "    predictions = base_model.predict(X_test ) \n",
    "    #predictions = base_model.predict(dvalidation)\n",
    "    print (\"R^2:\",r2_score(y_test, predictions))\n",
    "    print (\"MAE:\",mean_absolute_error(y_test, predictions))\n",
    "    print (\"MSE:\",mean_squared_error(y_test, predictions))\n",
    "    r=r2_score(y_test, predictions)\n",
    "    mae=mean_absolute_error(y_test, predictions)\n",
    "    mse=mean_squared_error(y_test, predictions)\n",
    "    print (\"------------------------------------------\")\n",
    "    my_results.append((key,r,mae,mse))\n",
    "    \n",
    "    \n",
    "    error = predictions - y_test\n",
    "    my_dict[my_target_ditionary[key]] = { \"y_test\":y_test , \"predictions\":predictions , \"error\":error }\n",
    "#     error_plot = plt.hist(error, bins = 25)\n",
    "#     error_plot.xlabel(\"Prediction Error [MAE]\")\n",
    "#     error_plot.ylabel(\"Count\")\n",
    "#     error_plot.savefig(\"basemodel_error_bin_%s.png\"%(key),format=\"png\")\n",
    "    \n",
    "\n",
    "#     plt.scatter(y_test, predictions)\n",
    "#     plt.xlabel('True Values [MAE]')\n",
    "#     plt.ylabel('Predictions [MAE]')\n",
    "#     plt.axis('equal')\n",
    "#     plt.axis('square')\n",
    "#     plt.xlim([0,plt.xlim()[1]])\n",
    "#     plt.ylim([0,plt.ylim()[1]])\n",
    "#     _ = plt.plot([-100, 100], [-100, 100])\n",
    "#     plt.savefig(\"MAE_base_model_%s.png\"%(key),format=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_summary = pd.DataFrame(my_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_summary.columns = [\"Target\",\"R^2\",\"MAE\",\"MSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (result_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in my_dict:\n",
    "    print (key)\n",
    "    plt.figure()\n",
    "    plt.hist(my_dict[key][\"error\"], bins = 25)\n",
    "    plt.xlabel(\"Prediction Error [MAE]\")\n",
    "    _ = plt.ylabel(\"Count\")\n",
    "    plt.savefig(\"basemodel_error_bin_%s.png\"%(key),format=\"png\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in my_dict:\n",
    "    print (key)\n",
    "    plt.figure()\n",
    "    plt.scatter(my_dict[key][\"y_test\"], my_dict[key][\"predictions\"])\n",
    "    plt.xlabel('True Values [MAE]')\n",
    "    plt.ylabel('Predictions [MAE]')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,plt.xlim()[1]])\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    _ = plt.plot([-100, 100], [-100, 100])\n",
    "    plt.savefig(\"MAE_base_model_%s.png\"%(key),format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y_test, predictions)\n",
    "# plt.xlabel('True Values [MAE]')\n",
    "# plt.ylabel('Predictions [MAE]')\n",
    "# plt.axis('equal')\n",
    "# plt.axis('square')\n",
    "# plt.xlim([0,plt.xlim()[1]])\n",
    "# plt.ylim([0,plt.ylim()[1]])\n",
    "# _ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_plot = plt.hist(error, bins = 25)\n",
    "# plt.xlabel(\"Prediction Error [MAE]\")\n",
    "# plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "!ls synapse_DREAM_challenge/CELL_LINES/ | wc -l \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = xgb.XGBRFRegressor(n_jobs=-1,n_estimators=8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled , y[\"p.ERK\"], test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/didier/anaconda3/envs/dask-tutorial/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "d_train = xgb.DMatrix(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.core.DMatrix"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'silent':1, 'objective':'reg:lineal', 'booster':'gbtree', 'base_score':3}\n",
    "param = {'silent':1,  'booster':'gbtree', 'base_score':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gamma regression, we need to set the objective to 'reg:gamma', it also suggests\n",
    "# to set the base_score to a value between 1 to 5 if the number of iteration is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rest of settings are the same\n",
    "watchlist = [(d_test, 'eval'), (d_train, 'train')]\n",
    "num_round = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.970925\ttrain-rmse:0.97049\n",
      "[1]\teval-rmse:0.872155\ttrain-rmse:0.871691\n",
      "[2]\teval-rmse:0.816031\ttrain-rmse:0.815587\n",
      "[3]\teval-rmse:0.784241\ttrain-rmse:0.783816\n",
      "[4]\teval-rmse:0.765851\ttrain-rmse:0.7654\n",
      "[5]\teval-rmse:0.754224\ttrain-rmse:0.753746\n",
      "[6]\teval-rmse:0.746945\ttrain-rmse:0.746423\n",
      "[7]\teval-rmse:0.741515\ttrain-rmse:0.74097\n",
      "[8]\teval-rmse:0.737801\ttrain-rmse:0.737218\n",
      "[9]\teval-rmse:0.734354\ttrain-rmse:0.733738\n",
      "[10]\teval-rmse:0.731935\ttrain-rmse:0.731309\n",
      "[11]\teval-rmse:0.729572\ttrain-rmse:0.728933\n",
      "[12]\teval-rmse:0.727683\ttrain-rmse:0.727031\n",
      "[13]\teval-rmse:0.72577\ttrain-rmse:0.725105\n",
      "[14]\teval-rmse:0.724828\ttrain-rmse:0.724156\n",
      "[15]\teval-rmse:0.723497\ttrain-rmse:0.722816\n",
      "[16]\teval-rmse:0.721807\ttrain-rmse:0.721108\n",
      "[17]\teval-rmse:0.720677\ttrain-rmse:0.719966\n",
      "[18]\teval-rmse:0.719643\ttrain-rmse:0.718908\n",
      "[19]\teval-rmse:0.718642\ttrain-rmse:0.717904\n",
      "[20]\teval-rmse:0.717804\ttrain-rmse:0.717052\n",
      "[21]\teval-rmse:0.716527\ttrain-rmse:0.715771\n",
      "[22]\teval-rmse:0.715699\ttrain-rmse:0.714937\n",
      "[23]\teval-rmse:0.714826\ttrain-rmse:0.714064\n",
      "[24]\teval-rmse:0.714282\ttrain-rmse:0.713505\n",
      "[25]\teval-rmse:0.713599\ttrain-rmse:0.712818\n",
      "[26]\teval-rmse:0.713026\ttrain-rmse:0.712236\n",
      "[27]\teval-rmse:0.712218\ttrain-rmse:0.711404\n",
      "[28]\teval-rmse:0.711487\ttrain-rmse:0.710662\n",
      "[29]\teval-rmse:0.71052\ttrain-rmse:0.709694\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, d_train, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
